{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-74a045a251c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/elice/data/train_data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[1;32m    352\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    353\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 639\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('/elice/data_r1/train_data.json')\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df[\"rating\"].values\n",
    "\n",
    "a = []\n",
    "for i, j in enumerate(y):\n",
    "    if j <= 3:\n",
    "        a.append(\"NEG\")\n",
    "    elif j >= 4 and j <= 7:\n",
    "        a.append(\"NEU\")\n",
    "    else:\n",
    "        a.append(\"POS\")\n",
    "        \n",
    "df[\"char\"] = a\n",
    "df.tail()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(df.char).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, sys\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "class BayesianFilter:\n",
    "    \"\"\" 베이지안 필터 \"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set() # 출현한 단어 기록\n",
    "        self.word_dict = {} # 카테고리마다의 출현 횟수 기록\n",
    "        self.category_dict = {} # 카테고리 출현 횟수 기록\n",
    "    # 형태소 분석하기 --- (※1)\n",
    "    def split(self, text):\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        # 단어의 기본형 사용\n",
    "        malist = twitter.pos(text, norm=True, stem=True)\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점 등은 대상에서 제외 \n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    # 단어와 카테고리의 출현 횟수 세기 --- (※2)\n",
    "    def inc_word(self, word, category):\n",
    "        # 단어를 카테고리에 추가하기\n",
    "        if not category in self.word_dict:\n",
    "            self.word_dict[category] = {}\n",
    "        if not word in self.word_dict[category]:\n",
    "            self.word_dict[category][word] = 0\n",
    "        self.word_dict[category][word] += 1\n",
    "        self.words.add(word)\n",
    "    def inc_category(self, category):\n",
    "        # 카테고리 계산하기\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category] = 0\n",
    "        self.category_dict[category] += 1\n",
    "    \n",
    "    # 텍스트 학습하기 --- (※3)\n",
    "    def fit(self, text, category):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        word_list = self.split(text)\n",
    "        for word in word_list:\n",
    "            self.inc_word(word, category)\n",
    "        self.inc_category(category)\n",
    "    \n",
    "    # 단어 리스트에 점수 매기기--- (※4)\n",
    "    def score(self, words, category):\n",
    "        score = math.log(self.category_prob(category))\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, category))\n",
    "        return score\n",
    "    \n",
    "    # 예측하기 --- (※5)\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize \n",
    "        words = self.split(text)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category, score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "    # 카테고리 내부의 단어 출현 횟수 구하기\n",
    "    def get_word_count(self, word, category):\n",
    "        if word in self.word_dict[category]:\n",
    "            return self.word_dict[category][word]\n",
    "        else:\n",
    "            return 0\n",
    "    # 카테고리 계산\n",
    "    def category_prob(self, category):\n",
    "        sum_categories = sum(self.category_dict.values())\n",
    "        category_v = self.category_dict[category]\n",
    "        return category_v / sum_categories\n",
    "        \n",
    "    # 카테고리 내부의 단어 출현 비율 계산 --- (※6)\n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1 # ---(※6a)\n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        return n / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf = BayesianFilter()\n",
    "\n",
    "for i in range(1, 700000):\n",
    "    bf.fit(df[i-1:i][\"review\"].values[0], df[i-1:i][\"char\"].values[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre, scorelist = bf.predict(df[699998:699999][\"review\"].values[0])\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)\n",
    "print(df[699998:699999][\"review\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_in = open(\"/elice/data_r1/test.input\", 'r')\n",
    "\n",
    "p = []\n",
    "lines = test_in.readlines()\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    pre, scorelist = bf.predict(line)\n",
    "    p.append(pre)\n",
    "    print(\"결과 =\", pre)\n",
    "test_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "test_out = open(\"/elice/data_r1/test.output\", 'r')\n",
    "\n",
    "o = []\n",
    "lines = test_out.readlines()\n",
    "for line in lines:\n",
    "    m = re.match('[A-Z]+', line)\n",
    "    o.append(m[0])\n",
    "    print(m[0])\n",
    "test_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(p.count('POS'))\n",
    "print(p.count('NEU'))\n",
    "print(p.count('NEG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(o)\n",
    "print(o.count('POS'))\n",
    "print(o.count('NEU'))\n",
    "print(o.count('NEG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del p[-1]\n",
    "#len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(o)):\n",
    "    if o[i] == p[i]:\n",
    "        t.append(\"True\")\n",
    "    else:\n",
    "        t.append(\"false\")\n",
    "\n",
    "#print(t)\n",
    "print(t.count('True')/len(o)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as submission:\n",
    "    for item in p:\n",
    "        submission.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import elice_challenge as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#제출파일 테스트\n",
    "ec.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grading_in = open(\"/elice/data_r1/grading.input\", 'r')\n",
    "\n",
    "final = []\n",
    "lines = grading_in.readlines()\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    pre, scorelist = bf.predict(line)\n",
    "    final.append(pre)\n",
    "    print(\"결과 =\", pre)\n",
    "grading_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as submission:\n",
    "    for item in final:\n",
    "        submission.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#제출 및 채점\n",
    "ec.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
